services:
  backend:
    container_name: backend
    image: nilsherzig/llocalsearch-backend:latest
    environment:
      ##### change these
      # the ip / url of YOUR Ollama server
      - OLLAMA_HOST=http://192.168.0.109:11434

      ##### no need to change these
      # the url of the chroma db
      - CHROMA_DB_URL=http://chromadb:8000

      # the url of the redis db
      - SEARXNG_DOMAIN=http://searxng:8080

      # the maximum amount of iterations the agent will run to find your answer
      - MAX_ITERATIONS=30
    networks:
      - llm_network

  frontend:
    depends_on:
      - backend
    container_name: frontend
    image: nilsherzig/llocalsearch-frontend:latest
    ports:
      - '3000:4173'
    networks:
      - llm_network

  chromadb:
    container_name: chromadb
    image: chromadb/chroma
    networks:
      - llm_network

  redis:
    container_name: redis
    image: docker.io/library/redis:alpine
    command: redis-server --save 30 1 --loglevel warning
    networks:
      - searxng
    volumes:
      - redis-data:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE

  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    networks:
      - searxng
      - llm_network
    volumes:
      - ./searxng:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: 'json-file'
      options:
        max-size: '1m'
        max-file: '1'

networks:
  llm_network:
    driver: bridge
  searxng:
    ipam:
      driver: default

volumes:
  redis-data:
